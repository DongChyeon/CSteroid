# CPU와 메모리 구조

CPU는 연산 속도에 비해 메모리 접근 속도가 매우 느림
이를 보완하기 위해 빠르지만 작은 저장소와 느리지만 큰 저장소를 계층적으로 구성함
이를 메모리 계층 구조라고 함

## CPU 메모리 계층별 특징

1. 레지스터 (Register)

   * CPU 내부에 있는 가장 빠른 저장 장치
   * 연산 시 직접 사용하는 값이 저장됨
   * 용량은 수십\~수백 바이트 수준임

2. 캐시 (Cache: L1, L2, L3)

   * CPU와 메인 메모리(RAM) 사이의 속도 차이를 줄이는 역할
   * L1은 CPU 코어 바로 옆에 있어 가장 빠르지만 용량은 작음 (수십 KB)
   * L2, L3로 갈수록 용량은 크고 속도는 느려짐
   * 캐시 히트 시 CPU는 빠르게 데이터 접근 가능, 미스 시 RAM까지 접근해야 하므로 지연 발생

3. 메인 메모리 (RAM)

   * 대규모 데이터를 저장하는 휘발성 메모리
   * CPU 입장에서는 느리지만, SSD보다는 빠름
   * 수 GB\~수십 GB 수준으로 사용됨

4. 보조 저장장치 (SSD, HDD)

   * 비휘발성, 전원이 꺼져도 데이터 유지
   * CPU 입장에서는 가장 느린 계층

[지역성(Locality)]
* 시간적 지역성: 최근에 사용한 데이터는 가까운 시일 내에 다시 사용될 가능성이 높음
* 공간적 지역성: 특정 주소의 데이터에 접근하면, 인접한 주소의 데이터도 함께 접근할 가능성이 높음
  → 예: 배열이나 리스트를 순차적으로 탐색할 때, 연속된 메모리 접근으로 성능이 향상됨

자바에서 for문으로 배열을 순차 탐색하면 CPU가 데이터를 한 번에 캐시로 불러올 수 있어 성능이 좋아짐

## 코드 실행 흐름과 메모리

1. 실행 파일은 디스크에 저장되어 있음
2. CPU는 디스크에 직접 접근하지 않고, 운영체제가 필요한 부분만 메모리(RAM)에 올림
3. 메모리의 일부가 캐시와 레지스터로 복사되어 실제로 실행됨
   → 디스크 → 메모리 → 캐시 → 레지스터 → 연산

실행 파일이 메모리에 적재되면 다음 영역으로 나뉨

* 코드 영역: 기계어 명령어와 함수들이 저장됨
* 데이터 영역: 전역 변수, 정적 변수, 상수 등이 저장됨
* 힙 영역: 런타임 시 동적으로 생성되는 객체가 저장됨
   * ex) Java에서 new 키워드로 생성한 객체
* 스택 영역: 메서드 호출 시 지역 변수, 매개변수, 리턴 주소 등이 저장됨

CPU는 필요한 데이터만 캐시로 가져와 명령을 수행함

[전체 파일을 메모리에 올리지 않는 이유]

메모리 용량에는 한계가 있음  
- 실행 파일이 수백 MB, 수 GB가 될 수도 있는데 모든 프로그램을 한 번에 메모리에 올리면 RAM이 금방 가득 차서 실행이 불가능해짐

실행 시 필요한 부분만 페이지 단위(보통 4KB)로 메모리에 올림
-  운영체제는 프로그램 전체를 한꺼번에 적재하지 않고, 현재 실행에 필요한 코드와 데이터만 잘라서 메모리에 적재함 
-  이 단위를 페이지(Page)라고 하며 보통 4KB 크기를 사용함

사용하지 않는 부분은 디스크에 그대로 둠
- 필요할 때만 디스크에서 해당 페이지를 불러오는 방식(요구 페이징, Demand Paging)을 사용함
- 만약 메모리에 자리가 부족하면, 운영체제가 사용하지 않는 페이지를 다시 디스크로 내보내고(스왑) 새로운 페이지를 불러옴

이를 통해 프로그램 크기가 실제 메모리 크기보다 커도 실행 가능함
예를 들어, RAM이 8GB인데도 20GB짜리 프로그램을 실행할 수 있는 이유가 바로 가상 메모리와 페이지 교체 덕분임

## CPU 캐시 일관성 문제

여러 CPU 코어가 같은 메모리 주소를 각자 캐시에 저장할 때 값이 달라질 수 있음. 이를 캐시 일관성(Cache Coherency) 문제라고 함

* 메모리에 변수 A = 5
* 코어1, 코어2 모두 A = 5를 캐시에 저장
* 코어1이 A를 10으로 바꾸면, 코어2는 여전히 5를 갖고 있음

이를 해결하기 위해 MESI 프로토콜 등 하드웨어 규칙 사용 Modified, Exclusive, Shared, Invalid 상태로 캐시 간 데이터 최신 여부를 추적
=> 이 부분은 하드웨어에서 자동으로 처리되므로, 커널 개발을 할 것이 아니라면 건드릴 수 없음

*참고) 유저 모드(User Mode)와 커널 모드(Kernel Mode)
* JVM, 파이썬 등 우리가 실행하는 응용 프로그램은 모두 유저 모드에서 실행됨
* 유저 모드에서는 하드웨어에 직접 접근할 수 없음
* 실제 메모리 주소(물리 주소)는 운영체제가 관리함
  => 프로그램은 운영체제가 제공하는 가상 주소만 사용 가능

ex) 자바에서 int a = 10처럼 변수를 선언하면 운영체제가 가상 메모리 공간 어딘가에 메모리를 할당하고, 이를 가상 주소로 접근함

CPU는 MMU(메모리 관리 장치)와 TLB(주소 변환 캐시)를 사용해 가상 주소 ↔ 물리 주소를 실시간으로 변환함

JVM은 하드웨어를 직접 제어하지 않으며, CPU 캐시 일관성 같은 문제는 전적으로 하드웨어가 처리함

## OS 에서 메모리 관리

OS는 컴퓨터 하드웨어를 관리하는 소프트웨어임

* CPU가 데이터를 요청했는데 메모리에 없으면 디스크까지 접근해야 하므로 성능이 크게 저하됨
* 따라서 OS는 자주 사용하는 데이터는 메모리에 남기고, 오래 사용하지 않은 데이터는 제거할 수 있도록 함
  => 이를 위해 LRU (Least Recently Used) 같은 페이지 교체 알고리즘을 사용함 Redis, JVM GC, 데이터베이스 캐시 등에서도 유사한 원리 사용

1. 실행 파일은 디스크에서 직접 실행되지 않고, 필요한 부분만 메모리에 적재됨
2. 메모리는 코드, 전역 변수, 힙, 스택 등으로 구성됨
3. CPU는 필요한 데이터를 캐시/레지스터에 로드해 처리함
4. 운영체제는 LRU 등의 페이지 교체 알고리즘으로 메모리를 관리함
5. 성능을 높이기 위해선 디스크 접근을 줄이고, CPU가 자주 쓰는 데이터를 메모리에 올리는 것이 핵심임
   => 히트율(Hit Rate): CPU가 데이터를 찾을 때 메모리에 데이터가 있으면 히트율이 높다고 하며, 없으면 디스크까지 접근해야 하므로 성능이 저하

*시스템 구성 요소별 메모리 활용
* 웹 서버: 디스크 I/O를 줄이기 위해 메모리 캐시를 적극적으로 활용함
* 데이터베이스: InnoDB Buffer Pool 등은 "디스크 대신 메모리에서 읽자"는 전략임
* JVM: 힙 크기 조정, GC 전략 등을 통해 메모리 적재·회수의 효율성을 높이는 것이 목적임

