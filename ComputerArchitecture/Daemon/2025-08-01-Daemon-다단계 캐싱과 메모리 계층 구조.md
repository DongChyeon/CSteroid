---
date: 2025-08-01
user: Daemon
topic: "다단계 캐싱과 메모리 계층 구조"
---

# 다단계 캐싱과 메모리 계층 구조

프로세서와 주메모리 간의 속도 차이를 해결하기 위해 여러 단계의 캐시를 배치하여 전체 시스템 성능을 최적화합니다.

## 메모리 계층 구조의 기본 개념

컴퓨터에서 가장 빠른 메모리는 매우 비싸고 용량이 작습니다. 반면에 용량이 큰 메모리는 느리고 상대적으로 저렴합니다. 메모리 계층 구조는 속도가 빠르고 용량이 작은 메모리부터 속도가 느리고 용량이 큰 메모리까지 계층적으로 배치한 구조입니다. 각 계층은 지역성 원리(locality principle)를 활용하여 자주 사용되는 데이터를 상위 계층에 보관함으로써 평균 메모리 접근 시간을 단축시킵니다.

### 지역성 원리

**시간 지역성(Temporal Locality)**: 최근에 접근한 데이터나 명령어는 또 다시 활용할 경우가 많습니다. 예를 들어, 반복문의 카운터 변수나 함수 내의 지역 변수들이 이에 해당합니다.

**공간 지역성(Spatial Locality)**: 말 그대로 시간이 아닌 공간 특성을 잘 생각해보면 특정 메모리 위치에 접근하면 인근 위치의 데이터에도 접근할 가능성이 높습니다. 배열의 순차적 접근이나 명령어의 순차적 실행이 대표적인 예입니다.

## 메모리 계층의 구성

<img width="850" height="468" alt="image" src="https://github.com/user-attachments/assets/4ae21ab5-f911-41e7-920b-1459ec1e3697" />

### 1단계: 레지스터 (Registers)

- **위치**: CPU 내부
- **용량**: 수십 개 × 32/64비트
- **접근 시간**: 1 클록 사이클 미만
- **특징**: 가장 빠른 메모리, 컴파일러나 프로그래머가 직접 관리

### 2단계: L1 캐시 (Level 1 Cache)

- **위치**: CPU 코어 내부
- **용량**: 16KB ~ 64KB (명령어 캐시와 데이터 캐시로 분리)
- **접근 시간**: 1-3 클록 사이클
- **특징**: 하버드 아키텍처 적용으로 명령어와 데이터 분리 저장

→ 여기서 하버드 아키텍처는 명령어와 데이터가 같은 메모리에 저장되어있어서 한 개의 파이프로 번갈아서 전송하는 폰 노이만 아키텍처와는 다르게 별도 메모리에 저장해서 두 개의 파이프가 존재하는 것을 말합니다.

하버드 방식은 명령어와 데이터를 가져오는 것이 동시에 가능하기 때문에 병목 현상을 해결할 수 있습니다. 예를 들어 실제 동작 상황에서 CPU가 FPS게임류에서 총 발사와 총을 발사했으니 총알 개수도 달라지는데, 해당 데이터도 같이 가져올 수 있기 때문에 현대에서는 폰 노이만이 아닌 자연스럽게 하버드를 채택할 수밖에 없습니다.

다만, 메모리와 버스가 2배로 필요해지고 물리적인 칩의 크기도 올라가기 때문에 L1 캐시에만 순수 하버드로 적용하고 그 외 L2, L3 캐시, 그리고 주메모리에서는 통합된 하이브리드 구조를 사용합니다.

### 3단계: L2 캐시 (Level 2 Cache)

- **위치**: CPU 코어 내부 또는 코어와 매우 가까운 위치
- **용량**: 256KB ~ 1MB
- **접근 시간**: 10-20 클록 사이클
- **특징**: L1보다 크지만 상대적으로 느림, 통합 캐시로 구성

### 4단계: L3 캐시 (Level 3 Cache)

- **위치**: CPU 패키지 내부, 여러 코어가 공유
- **용량**: 8MB ~ 32MB
- **접근 시간**: 30-50 클록 사이클
- **특징**: 멀티코어 시스템에서 코어 간 데이터 공유 역할

### 5단계: 주메모리 (Main Memory, RAM)

- **위치**: 메인보드의 DIMM 슬롯
- **용량**: 4GB ~ 128GB 이상
- **접근 시간**: 200-300 클록 사이클
- **특징**: DRAM 기술 사용, 휘발성 메모리 → 컴퓨터를 끄면 데이터가 날아감.

### 6단계: 보조저장장치 (Secondary Storage)

- **위치**: SSD, HDD 등 독립적인 저장 장치
- **용량**: 수백 GB ~ 수십 TB
- **접근 시간**: 수백만 클록 사이클
- **특징**: 비휘발성, 가상 메모리 시스템의 스왑 공간으로 활용 → 컴퓨터를 꺼도 데이터가 날아가지 않음.

## 캐시 동작 원리

<img width="1280" height="627" alt="image" src="https://github.com/user-attachments/assets/075613d7-2904-471c-ab76-098891d806e2" />

### 캐시 히트와 미스

**캐시 히트**: 요청된 데이터가 캐시에 있는 경우로, 빠른 속도로 데이터를 반환할 수 있습니다. 히트율이 높을수록 시스템 성능이 향상됩니다.

**캐시 미스**: 요청된 데이터가 캐시에 없는 경우로, 하위 메모리 계층에서 데이터를 가져와야 합니다. 미스의 종류에는 콜드 미스(최초 접근), 용량 미스(캐시 용량 부족), 충돌 미스(매핑 방식으로 인한 충돌)가 있습니다.

### 캐시 매핑 방식

**직접 매핑(Direct Mapping)**: 각자 정해진 자리가 있는, 다시 말해서 각 메모리 블록이 캐시의 특정 위치에만 저장될 수 있는 방식입니다. 구현이 간단하지만 충돌 미스가 자주 발생할 수 있습니다.

**완전 연관 매핑(Fully Associative)**: 메모리 블록이 캐시의 어느 위치에나 저장될 수 있는 방식입니다. 충돌 미스는 적지만 하드웨어 복잡도가 높습니다.

**세트 연관 매핑(Set Associative)**: 직접 매핑과 완전 연관 매핑의 장점을 혼합한 매핑 방식으로, 캐시를 여러 세트로 나누고 각 세트 내에서는 완전 연관 방식을 사용합니다.

### 교체 정책

**LRU(Least Recently Used)**: 가장 오래 사용되지 않은 블록을 교체하는 방식으로, 시간 지역성을 잘 활용합니다.

**FIFO(First In First Out)**: 가장 먼저 들어온 블록을 먼저 교체하는 방식으로, 구현이 간단하지만 성능은 LRU보다 떨어질 수 있습니다.

**Random**: 무작위로 블록을 선택하여 교체하는 방식으로, 하드웨어 구현이 매우 간단합니다.

## 쓰기 정책

### Write-Through

모든 쓰기 연산이 캐시와 하위 메모리에 동시에 수행되는 방식입니다. 데이터 일관성은 보장되지만 쓰기 성능이 떨어집니다.

### Write-Back (Write-Behind)

쓰기 연산을 캐시에만 수행하고, 해당 블록이 교체될 때 하위 메모리에 반영하는 방식입니다. 성능은 좋지만 더티 비트 관리가 필요합니다.

## 다단계 캐시의 설계 고려사항

### 포함성(Inclusivity)

**포함(Inclusive)**: 상위 캐시의 모든 데이터가 하위 캐시에도 존재하는 방식으로, 일관성 유지가 쉽지만 하위 캐시 공간이 낭비될 수 있습니다.

**비포함(Exclusive)**: 상위 캐시와 하위 캐시가 서로 다른 데이터를 저장하는 방식으로, 메모리 활용도는 높지만 관리가 복잡합니다.

### 할당 정책

**Write Allocate**: 쓰기 미스 시 해당 블록을 캐시로 가져오는 방식
**No Write Allocate**: 쓰기 미스 시 캐시로 가져오지 않는 방식

자주 방문하는 사이트 → L1 캐시로 즉시 로딩

가끔 보는 사이트 → L2 캐시로 빠른 로딩

게임 플레이시 현재 화면의 그래픽은 레지스터와 L1 캐시로 처리하고 주변 지역 데이터는 L2, L3 캐시로 처리함

## 성능 최적화 기법

### 프리페칭(Prefetching)

프로세서가 데이터를 요청하기 전에 미리 캐시로 가져오는 기법입니다. 하드웨어 프리페칭과 소프트웨어 프리페칭이 있으며, 공간 지역성을 활용하여 성능을 향상시킵니다.

### 멀티포트 캐시

동시에 여러 메모리 접근을 처리할 수 있는 캐시 구조로, 슈퍼스칼라 프로세서에서 중요합니다.

### 논블로킹 캐시

캐시 미스가 발생해도 다른 메모리 접근을 계속 처리할 수 있는 구조로, 메모리 레벨 병렬성을 활용합니다.

## 멀티코어 환경에서의 캐시 일관성

### 캐시 일관성 문제

여러 코어가 같은 데이터의 복사본을 각자의 캐시에 가지고 있을 때, 한 코어가 데이터를 수정하면 다른 코어의 캐시에 있는 복사본이 무효화됩니다.

### MESI 프로토콜

**Modified**: 해당 캐시 라인이 수정되었고 유일한 유효 복사본
**Exclusive**: 해당 캐시 라인이 유일하지만 수정되지 않음
**Shared**: 여러 캐시에 유효한 복사본이 존재
**Invalid**: 해당 캐시 라인이 무효함

현대 CPU에서 Intel은 큰 L3 중심으로 단일 스레드 성능을 최적화시키고 AMD는 L2와 L3를 균형 있게 설계해서 멀티스레드 성능을 최적화시킴.

## 가상 메모리와의 상호작용

### TLB(Translation Lookaside Buffer)

가상 주소를 물리 주소로 변환하는 페이지 테이블 엔트리를 캐싱하는 특수한 캐시입니다. 주소 변환 속도를 크게 향상시킵니다.

### 가상 vs 물리 캐시

**가상 캐시**: 가상 주소를 사용하여 빠른 접근이 가능하지만 aliasing 문제 발생
**물리 캐시**: 물리 주소를 사용하여 일관성은 보장되지만 주소 변환 지연 발생
